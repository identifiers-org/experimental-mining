{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script provides some reporting on the resolver data from identifiers.org\n",
    "#\n",
    "# Author: Manuel Bernal Llinares <mbdebian@gmail.com>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas\n",
    "import requests\n",
    "import threading\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint from where the information is coming\n",
    "identifiersorg_resolver_data_url = \"https://identifiers.org/rest/collections/expand\"\n",
    "metadata_service_endpoint_from_url = \"http://localhost:8082/getMetadataForUrl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pseudo-random number generator\n",
    "random.seed(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def make_rest_request_content_type_json(url):\n",
    "    # TODO - Magic number here!!!\n",
    "    n_attempts = 42\n",
    "    response = None\n",
    "    while n_attempts:\n",
    "        n_attempts -= 1\n",
    "        try:\n",
    "            response = requests.get(url, headers={\"Content-Type\": \"application/json\"})\n",
    "        except Exception as e:\n",
    "            # Any possible exception counts towards the attempt counter\n",
    "            # Random wait - TODO - Another magic number!!!\n",
    "            time.sleep(random.randint(30))\n",
    "            continue\n",
    "        if response.ok:\n",
    "            return response.json()\n",
    "        # Random wait - TODO - Another magic number!!!\n",
    "        time.sleep(random.randint(10))\n",
    "    response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_for_url(url):\n",
    "    \"\"\"\n",
    "    This Helper queries the metadata service with a URL, \n",
    "    and returns its response back to the caller for further interpretation\n",
    "    \"\"\"\n",
    "    n_attempts = 42\n",
    "    response = None\n",
    "    while n_attempts:\n",
    "        n_attempts -= 1\n",
    "        try:\n",
    "            response = requests.post(metadata_service_endpoint_from_url, json={\"url\": url})\n",
    "        except Exception as e:\n",
    "            # Any possible exception counts towards the attempt counter\n",
    "            # Random wait - TODO - Another magic number!!!\n",
    "            time.sleep(random.randint(3))\n",
    "            continue\n",
    "        if response.ok:\n",
    "            print(\"[METADATA][OK] - '{}'\".format(url))\n",
    "            break\n",
    "        else:\n",
    "            print(\"[METADATA][ERROR] - '{}'\".format(url))\n",
    "            break\n",
    "        # Random wait - TODO - Another magic number!!!\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the resolver data\n",
    "resolver_dump = make_rest_request_content_type_json(identifiersorg_resolver_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workout how many prefixes there are in identifiers.org\n",
    "prefixes = [pid_entry['prefix'] for pid_entry in resolver_dump]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are #{} Compact ID prefixes registered in identifiers.org\".format(len(prefixes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of resources\n",
    "resource_prefixes = []\n",
    "for pid_entry in resolver_dump:\n",
    "    if 'resources' in pid_entry:\n",
    "        for resource in pid_entry['resources']:\n",
    "            if 'resourcePrefix' in resource:\n",
    "                resource_prefixes.append(resource['resourcePrefix'])\n",
    "            else:\n",
    "                print(\"NO RESOURCE PREFIX FOR: PID Entry Name '{}', Resource Information '{}'\".format(pid_entry['name'], resource['info']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resource_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_prefixes_distribution = Counter(resource_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_prefixes_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There #{} Resource Selectors in identifiers.org\".format(len(resource_prefixes_distribution.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(resource_prefixes_distribution.keys())\n",
    "values = [resource_prefixes_distribution.get(key) for key in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't like this Pie Chart\n",
    "fig1, ax1 = plt.subplots()\n",
    "fig1.set_size_inches(18, 5)\n",
    "ax1.bar(labels, values, 1/1.5, color=\"blue\")\n",
    "#ax1.pie(values, labels=labels, shadow=True, startangle=90)\n",
    "#ax1.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a report on metadata\n",
    "columns = ['PidEntryName',\n",
    "           'PidEntryPrefix',\n",
    "           'PidEntryUrl', \n",
    "           'ResourceInfo', \n",
    "           'ResourceInstitution', \n",
    "           'ResourceLocation', \n",
    "           'ResourceOfficial', \n",
    "           'ResourcePrefix', \n",
    "           'ResourceLocalId', \n",
    "           'WasMetadataFound', \n",
    "           'MetadataContent', \n",
    "           'ResourceTestUrl', \n",
    "           'MetadataServiceResponseStatus', \n",
    "           'MetadataServiceResponseError']\n",
    "metadata_report = pandas.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the URLs and initial report (I could have done everything in one pass, but this is just investigating the dataset)\n",
    "for pid_entry in resolver_dump:\n",
    "    entry = pandas.Series(['---'] * len(columns), index=columns)\n",
    "    entry.PidEntryName = pid_entry['name']\n",
    "    entry.PidEntryPrefix = pid_entry['prefix']\n",
    "    entry.PidEntryUrl = pid_entry['url']\n",
    "    if ('resources' not in pid_entry) or (not pid_entry['resources']):\n",
    "        metadata_report = metadata_report.append(entry, ignore_index=True)\n",
    "    for resource in pid_entry['resources']:\n",
    "        resource_entry = entry.copy()\n",
    "        resource_entry.ResourceInfo = resource['info']\n",
    "        resource_entry.ResourceInstitution = resource.get('institution', '---')\n",
    "        resource_entry.ResourceLocation = resource.get('location', '---')\n",
    "        resource_entry.ResourceOfficial = resource.get('official', '---')\n",
    "        resource_entry.ResourcePrefix = resource.get('resourcePrefix', '---')\n",
    "        resource_entry.ResourceLocalId = resource.get('localId', '---')\n",
    "        resource_entry.WasMetadataFound = 'No'\n",
    "        resource_entry.ResourceTestUrl = None\n",
    "        if ('accessURL' in resource) and ('localId' in resource):\n",
    "            resource_entry.ResourceTestUrl = resource['accessURL'].replace('{$id}', resource['localId'])\n",
    "        metadata_report = metadata_report.append(resource_entry, ignore_index=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_report.ResourceTestUrl.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel call to metadata service, this is a lot slower, good enough as proof of concept\n",
    "#metadata_requests = {index: threading.Thread(target=get_metadata_for_url(metadata_report.loc[index].ResourceTestUrl)) for index in range(metadata_report.shape[0]) if metadata_report.loc[index].ResourceTestUrl}\n",
    "\n",
    "# Parallel wrapper - Version using multiprocessing, it crashes within Jupyter\n",
    "#def metadata_request_parallel_wrapper(context, url):\n",
    "#    context.put(get_metadata_for_url(url))\n",
    "#metadata_requests = {index: multiprocessing.Process(target=metadata_request_parallel_wrapper, args=(multiprocessing.Queue(), metadata_report.loc[index].ResourceTestUrl),) for index in range(metadata_report.shape[0]) if metadata_report.loc[index].ResourceTestUrl}\n",
    "#metadata_requests = {index: multiprocessing.Process(target=get_metadata_for_url, args=(metadata_report.loc[index].ResourceTestUrl,)) for index in range(metadata_report.shape[0]) if metadata_report.loc[index].ResourceTestUrl}\n",
    "#[process.start() for process in metadata_requests.values()]\n",
    "\n",
    "# Another approach, with Thread Pool\n",
    "pool = Pool(processes=mp.cpu_count())\n",
    "indexes_to_process = [index for index in range(metadata_report.shape[0]) if metadata_report.loc[index].ResourceTestUrl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_requests = pool.map(get_metadata_for_url, metadata_report.ResourceTestUrl[indexes_to_process])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (index, response) in zip(indexes_to_process, metadata_requests):\n",
    "    if response.ok:\n",
    "        metadata_report.loc[index].WasMetadataFound = 'Yes'\n",
    "        metadata_report.loc[index].MetadataContent = response.json()['metadata']\n",
    "        print(\"[METADATA][OK] - '{}'\".format(metadata_report.loc[index].ResourceTestUrl))\n",
    "    else:\n",
    "        print(\"[METADATA][ERROR] - '{}'\".format(metadata_report.loc[index].ResourceTestUrl))\n",
    "    if 'errorMessage' in response.json():\n",
    "        metadata_report.loc[index].MetadataServiceResponseError = response.json()['errorMessage']\n",
    "    else:\n",
    "        metadata_report.loc[index].MetadataServiceResponseError = \"METADATA SERVICE ERROR\"\n",
    "        print(\"[METADATA][QUERY_ERROR] - '{}', response '{}'\".format(metadata_report.loc[index].ResourceTestUrl, response.json()))\n",
    "    metadata_report.loc[index].MetadataServiceResponseStatus = response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump report to file\n",
    "metadata_report.to_csv('metadata_report.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
